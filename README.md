# Regional Adversarial Perturbation

This repository contains the implementation of the regional adversarial attack proposed in the "Regional Image Perturbation Reduces Lp Norms of Adversarial Examples While Maintaining Model-to-model Transferability" published in 2020 International Conference on Machine Learning, Workshop in Uncertainty & Robustness in Deep Learning ([Link to the paper](https://arxiv.org/abs/...))

<img src="https://raw.githubusercontent.com/utkuozbulak/regional-adversarial-perturbation/master/media/localization.png">


## Citation
If you find the code in this repository useful for your research, consider citing our paper.

    @inproceedings{ozbulak2020regional,
        title={Regional Image Perturbation Reduces Lp Norms of Adversarial Examples While Maintaining Model-to-model Transferability},
        author={Ozbulak, Utku and Van Messem, Arnout and De Neve, Wesley},
        booktitle={published in 2020 International Conference on Machine Learning, Workshop in Uncertainty and Robustness in Deep Learning},
        year={2020}
    }


## Requirements
```
python > 3.5
torch >= 0.4.0
torchvision >= 0.1.9
numpy >= 1.13.0
PIL >= 1.1.7
```
